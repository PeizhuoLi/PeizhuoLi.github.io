
<!DOCTYPE html>
<html data-wf-domain="peizhuoli.github.io"
  data-wf-page="5e6fb768456f961381500a5f"
  data-wf-site="51e0d73d83d06baa7a00000f">
  <head>
    <meta charset="utf-8" />
    <title>WalkTheDog</title>
    <meta content="summary" name="twitter:card" /><meta
      content="width=device-width, initial-scale=1" name="viewport" />
    <link href="./walkthedog.css" rel="stylesheet" type="text/css" />
    <script>
      window.MathJax = {
        tex: {
          macros: {
            R: "\\mathbb{R}",
            exp: "\\mathrm{e}^{#1}",  // Macro with an argument
            X: "{\\bf X}",  // Macro with no argument
            A: "{\\bf A}",
            P: "{\\bf P}",
          }
        },
        startup: {
          pageReady: function() {
            return MathJax.startup.defaultPageReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script
      src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"
      type="text/javascript"></script>
    <script
      type="text/javascript">WebFont.load({  google: {    families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic","Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic","Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic","Changa One:400,400italic","Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic","Varela Round:400","Bungee Shade:regular","Roboto:300,regular,500"]  }});</script>
    <!--[if lt IE 9]><script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" type="text/javascript"></script><![endif]-->
    <script
      type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
    <link href="resources/logo.jpg" rel="shortcut icon" type="image/x-icon" />
    <link href="resources/logo.jpg" rel="apple-touch-icon" />
    <style>
      .video-player {
        margin-top: 50px;  /* Adds vertical space above the video */
        margin-bottom: 50px;  /* Adds vertical space below the video */
        width: 100%;    /* Sets the width of the video to 100% of its container's width */
      }
    </style>

  </head>
  <body>
    <div class="section hero nerf-_v2">
      <div class="container-2 nerf_header_v2 w-container">
        <h1 class="nerf_title_v2">WalkTheDog: Cross-Morphology Motion Alignment
          via Phase Manifolds</h1>
        <h1 class="nerf_subheader_v2">SIGGRAPH 2024</h1>
        <div class="nerf_authors_list_single w-row">
          <div class="w-col w-col-3 w-col-small-3 w-col-tiny-6"><a
              href="https://peizhuoli.github.io/" target="_blank"
              class="nerf_authors_v2">Peizhuo Li</a></div>
          <div class="w-col w-col-3 w-col-small-2 w-col-tiny-6"><a
              href="https://www.sebastianxstarke.com/" target="_blank"
              class="nerf_authors_v2">Sebastian Starke</a></div>
          <div class="w-col w-col-3 w-col-small-3 w-col-tiny-6"><a
              href="http://yutingye.info" target="_blank"
              class="nerf_authors_v2">Yuting Ye</a></div>
          <div class="w-col w-col-3 w-col-small-3 w-col-tiny-6"><a
              href="https://igl.ethz.ch/people/sorkine/" target="_blank"
              class="nerf_authors_v2">Olga Sorkine-Hornung</a></div>
        </div>
        <div>
          <span class="center">
            <video class="video-player" autoplay loop muted playsinline
              controls>
              <source src="./resources/video-teaser.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </span>

        </div>
        <div class="link_column_nerf_v2 w-row">
          <div class="w-col w-col-4 w-col-small-4 w-col-tiny-4">
            <a href="./papers/walk-the-dog-camera-ready-with-supp.pdf"
              target="_blank" class="link-block w-inline-block">
              <img
                src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5cab99df4998decfbf9e218e_paper-01.png"
                alt="paper" class="paper_img image-8 github_icon_nerf_v2" /></a>
          </div>
          <div class="w-col w-col-4 w-col-small-4 w-col-tiny-4">
            <a href="https://github.com/PeizhuoLi/walk-the-dog/" target="_blank"
              class="link-block w-inline-block">
              <img
                src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5cae3b53b42ebb3dd4175a82_68747470733a2f2f7777772e69636f6e66696e6465722e636f6d2f646174612f69636f6e732f6f637469636f6e732f313032342f6d61726b2d6769746875622d3235362e706e67.png"
                alt="paper" class="paper_img image-8 github_icon_nerf_v2" /></a>
          </div>
          <div class="column-2 w-col w-col-4 w-col-small-4 w-col-tiny-4"><a
              href="https://drive.google.com/drive/" target="_blank"
              class="link-block w-inline-block">
              <img
                src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5e7136849ee3b0a0c6a95151_database.svg"
                alt="paper" class="paper_img image-8_nerf nerf_db_icon" /></a>
          </div>
        </div>
        <div class="paper_code_nerf w-row">
          <div class="w-col w-col-4 w-col-small-4 w-col-tiny-4">
            <div class="text-block-2"><strong
                class="bold-text-nerf_v2">Paper</strong></div>
          </div>
          <div class="w-col w-col-4 w-col-small-4 w-col-tiny-4"><div
              class="text-block-2">
              <strong class="bold-text-nerf_v2">Code (Coming
                Soon)</strong></div>
          </div>
          <div class="w-col w-col-4 w-col-small-4 w-col-tiny-4">
            <div class="text-block-2"><strong class="bold-text-nerf_v2">Model
                (Coming Soon)</strong></div>
          </div>
        </div>
        <div
          class="nerf_slide_nav w-slider-nav w-slider-nav-invert w-round"></div></div></div>

    <div data-anchor="slide1" class="section nerf_section">
      <div class="grey_container w-container"><h2
          class="grey-heading_nerf">Overview Video</h2>
        <div style="padding-top:56.17021276595745%"
          id="w-node-e5e45b1d55ac-81500a5f" class="w-embed-youtubevideo">
          <iframe
            src="https://www.youtube.com/embed/tNVO2jqeTNw?rel=1&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0"
            frameBorder="0"
            style="position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:auto"
            allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <div data-anchor="slide1" class="section nerf_section">
      <div class="w-container">
        <h2 class="grey-heading_nerf">Abstract &amp; Method</h2>
        <span class="center">
          <img src="./resources/overview.png" class="overview_figure" />
        </span>
        <p class="paragraph-3 nerf_text">We introduce a novel approach to learn
          a common phase manifold from motion datasets across different
          characters, such as human and dog, using vector quantized periodic
          autoencoders. This manifold clusters semantically similar motions into
          the same connected component and aligns them temporally without
          supervision.

          <span class="center">
            <img src="./resources/arch.png" class="full_figure" />
          </span>
          <p class="paragraph-3 nerf_text">
            Starting with a short motion sequence \(\X \in \R^{J \times T}\),
            the encoder learns an intermediate representation using convolution.
            The representation is fed into the timing and the amplitude branch
            for predicting the phase \(\phi\), the frequency \(f\) and the
            amplitude \( \A \) of the pivot frame (rendered with mesh). A vector
            quantization (i.e. nearest neighbor search) is used in the amplitude
            branch to ensure the structure of the phase manifold. Note the
            codebook \( \mathcal{A}\) is shared among multiple VQ-PAEs. We
            calculate the embedding \(\P\) of the sequence assuming the
            frequency and amplitude stay constant in the sequence. The predicted
            phase manifold sequence is then passed through a convolutional
            decoder to reconstruct the input motion.
          </p>

          <p class="paragraph-3 nerf_text">The <i><span
                style="color: rgb(252,184,46);">input features</span></i> are
            extracted from the faces of the input mesh. After being projected
            into <i><span style="color: rgb(247,188,214);">embedding
                space</span></i> by a linear transformation, they are fed into
            the transformer encoder. Our manifold-aware self-attention layers
            explicitly involve local connectivities of the input geometry,
            making it possible to predict accurate dynamics caused by seams. The
            output of the transformer encoder is projected to the output
            features by another linear transformation. The <i><span
                style="color: rgb(18,176,38);">output features</span></i> are
            then used to predict the next frame of garment deformation.
          </p>

        </div></div>

      <div class="white_section_nerf">
        <div class="grey_container w-container">
          <h2 class="grey-heading_nerf">Results</h2>
          <p class="paragraph-3 nerf_text nerf_results_text">Our method can
            predict the dynamics of different garments driven by various unseen
            motions.</p>
          <span class="center">
            <video width="800" height="450" autoplay loop muted controls>
              <source src="./resources/video-teaser.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </span>
          <p class="paragraph-3 nerf_text nerf_results_text">Due to the nature
            of the feature and network design, our network can easily handle the
            dynamics of garments on an unseen body model.</p>
          <div class="center">
            <span class="center">
              <img src="images/unseen_body.gif" class="skin_result">
            </span>

            <p class="paragraph-3 nerf_text nerf_results_text">The
              manifold-aware design also enables our network to handle
              topological cuts that cannot be reflected with only spatial
              features.</p>
            <div class="center">
              <span class="center">
                <img src="images/seam_cut.gif" class="skin_result">
              </span>
            </div>
          </div></div>

        <div class="white_section_nerf">
          <div class="w-container">
            <h2 class="grey-heading_nerf">Comparisons</h2>
            <p class="paragraph-3 nerf_text nerf_results_text">Here we compare
              our result to a supervised method. It can be seen that our method
              models the dynamics of a loose garment better than the baseline:
            </p>
            <span class="center"><img src="images/comparison_ssch.gif"></span>
            <p class="paragraph-3 nerf_text nerf_results_text">Here we compare
              our result to a generalizable method driven by graph convolution.
              It can be seen that our method generates consistent results, while
              the graph convolution based method suffers from unnatural
              artifacts due to high resolution but limited receptive field:</p>
            <span class="center"><img src="images/comparison_hood.gif"></span>
          </div></div>

      </div>

      <div class="white_section_nerf">
        <div class="w-container">
          <h2 class="grey-heading_nerf">BibTeX</h2>
          <div class="grey_container w-container">
            <div class="bibtex">
              <pre><code>@inproceedings{Li2024walkthedog,
  title={WalkTheDog: Cross-Morphology Motion Alignment via Phase Manifolds},
  author={Li, Peizhuo and Starke, Sebastian and Ye, Yuting and Sorkine-Hornung, Olga},
  booktitle = {SIGGRAPH, Technical Papers},
  year = {2024},
  doi={10.1145/3641519.3657508}
}
</code></pre>
            </div>
          </div>
        </div>
      </div>
</body></html>
